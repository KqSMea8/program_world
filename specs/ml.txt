什么是机器学习12
为什么要使用机器学习12
机器学习系统的种类15
监督式/无监督式学习16
批量学习和在线学习21
基于实例与基于模型的学习24
机器学习的主要挑战29
训练数据的数量不足29
训练数据不具代表性30
质量差的数据32
无关特征32
训练数据过度拟合33
训练数据拟合不足34
退后一步35
测试与验证35
练习37
第2章 端到端的机器学习项目39
使用真实数据39
观察大局40
框架问题41
选择性能指标42
检查假设45
获取数据45
创建工作区45
下载数据48
快速查看数据结构49
创建测试集52
从数据探索和可视化中获得洞见56
将地理数据可视化57
寻找相关性59
试验不同属性的组合61
机器学习算法的数据准备62
数据清理63
处理文本和分类属性65
自定义转换器67
特征缩放68
转换流水线68
选择和训练模型70
培训和评估训练集70
使用交叉验证来更好地进行评估72
微调模型74
网格搜索74
随机搜索76
集成方法76
分析最佳模型及其错误76
通过测试集评估系统77
启动、监控和维护系统78
试试看79
练习79
第3章 分类80
MNIST80
训练一个二元分类器82
性能考核83
使用交叉验证测量精度83
混淆矩阵84
精度和召回率86
精度/召回率权衡87
ROC曲线90
多类别分类器93
错误分析95
多标签分类98
多输出分类99
练习100
第4章 训练模型102
线性回归103
标准方程104
计算复杂度106
梯度下降107
批量梯度下降110
随机梯度下降112
小批量梯度下降114
多项式回归115
学习曲线117
正则线性模型121
岭回归121
套索回归123
弹性网络125
早期停止法126
逻辑回归127
概率估算127
训练和成本函数128
决策边界129
Softmax回归131
练习134
第5章 支持向量机136
线性SVM分类136
软间隔分类137
非线性SVM分类139
多项式核140
添加相似特征141
高斯RBF核函数142
计算复杂度143
SVM回归144
工作原理145
决策函数和预测146
训练目标146
二次规划148
对偶问题149
核化SVM149
在线SVM151
练习152
第6章 决策树154
决策树训练和可视化154
做出预测155
估算类别概率157
CART训练算法158
计算复杂度158
基尼不纯度还是信息熵159
正则化超参数159
回归161
不稳定性162
练习163
第7章 集成学习和随机森林165
投票分类器165
bagging和pasting168
Scikit-Learn的bagging和pasting169
包外评估170
Random Patches和随机子空间171
随机森林172
极端随机树173
特征重要性173
提升法174
AdaBoost175
梯度提升177
堆叠法181
练习184
第8章 降维185
维度的诅咒186
数据降维的主要方法187
投影187
流形学习189
PCA190
保留差异性190
主成分191
低维度投影192
使用Scikit-Learn192
方差解释率193
选择正确数量的维度193
PCA压缩194
增量PCA195
随机PCA195
核主成分分析196
选择核函数和调整超参数197
局部线性嵌入199
其他降维技巧200
练习201
第二部分 神经网络和深度学习
第9章 运行TensorFlow205
安装207
创建一个计算图并在会话中执行208
管理图209
节点值的生命周期210
TensorFlow中的线性回归211
实现梯度下降211
手工计算梯度212
使用自动微分212
使用优化器214
给训练算法提供数据214
保存和恢复模型215
用TensorBoard来可视化图和训练曲线216
命名作用域219
模块化220
共享变量222
练习225
第10章 人工神经网络简介227
从生物神经元到人工神经元227
生物神经元228
具有神经元的逻辑计算229
感知器230
多层感知器和反向传播233
用TensorFlow的高级API来训练MLP236
使用纯TensorFlow训练DNN237
构建阶段237
执行阶段240
使用神经网络241
微调神经网络的超参数242
隐藏层的个数242
每个隐藏层中的神经元数243
激活函数243
练习244
第11章 训练深度神经网络245
梯度消失/爆炸问题245
Xavier初始化和He初始化246
非饱和激活函数248
批量归一化250
梯度剪裁254
重用预训练图层255
重用TensorFlow模型255
重用其他框架的模型256
冻结低层257
缓存冻结层257
调整、丢弃或替换高层258
模型动物园258
无监督的预训练259
辅助任务中的预训练260
快速优化器261
Momentum优化261
Nesterov梯度加速262
AdaGrad263
RMSProp265
Adam优化265
学习速率调度267
通过正则化避免过度拟合269
提前停止269
1和2正则化269
dropout270
最大范数正则化273
数据扩充274
实用指南275
练习276
第12章 跨设备和服务器的分布式TensorFlow279
一台机器上的多个运算资源280
安装280
管理GPU RAM282
在设备上操作284
并行执行287
控制依赖288
多设备跨多服务器288
开启一个会话290
master和worker服务290
分配跨任务操作291
跨多参数服务器分片变量291
用资源容器跨会话共享状态292
使用TensorFlow队列进行异步通信294
直接从图中加载数据299
在TensorFlow集群上并行化神经网络305
一台设备一个神经网络305
图内与图间复制306
模型并行化308
数据并行化309
练习314
第13章 卷积神经网络31